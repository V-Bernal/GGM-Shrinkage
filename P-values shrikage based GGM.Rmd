---
title: "P-values for shrinkage based GGM"
author: "Victor Bernal et al."
date: "Nov 12, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Description

This script reproduces the results published in  

* Title: EXACT HYPOTHESIS TESTING FOR SHRINKAGE BASED GGM.
* Publication: Bernal et al., Bioinformatics, https://doi.org/10.1093/bioinformatics/btz357 
* Author: Victor Bernal*, Rainer Bischoff, Victor Guryev, Marco Grzegorczyk, Peter Horvatovich
* Date created: 2018-11-12

Revision History  : Mar 09, 2019. Apr 26, 2020  
* Details: For the simulation of data and GGM estimation with the optimal shrinkage see [Sch?fer,J. and Strimmer,K. (2005a),  GeneNet 1.2.13. CRAN.]  
  
# Parameters
* p = Number of variables (e.g. genes)  
* n = Number of samples  
* number= Montecarlo iterations  
* rep = Times to repeat the simulation (for fixed p,n)  
* etaA = proportion of TP  
* alpha = significance level  
* eta0 = 1-etaA  

## Probability densities 
Here we compare qualitatively the standard vs the "shrunk" probability densities. As the shrinkage bias the partial correlation we expect that its density must account for the shrinkage value. Under the null hypothesis p-values are uniformly distributed in [0,1], we expect this bias will reflect on their distribution. 

# Load the libraries and functions
```{r ,  message = FALSE  }

#rm(list=ls())

library(GeneNet)
library(stats4)
library(Hmisc)
library(ggplot2)


set.seed(123)
#setwd("~/Desktop/GGM-Shrinkage")
source("shrinkagefunctions.R")
```

# Initialize the size of the network p, and the number of samples n 
```{r ,  message = FALSE  }
#***************************
# Initialize parameters
p<-100 # genes' number
etaA<-0.00 #proportion true positive correlations 
n<-c(30) # sample size
alpha<-0.05
number<-15 # MC iterations
```

# Simulate the network and data
```{r ,  message = FALSE  }
## Simulated pcorr and data
sim.pcor <-ggm.simulate.pcor(p, etaA)
sim.data <- ggm.simulate.data( n , sim.pcor)
temp <- sim.pcor[lower.tri(sim.pcor, diag = FALSE) ]
TP <-which(temp!=0 )
TN <- which(temp==0 )


```
# Reconstruct/estimate the network of partial correlations
```{r ,  message = FALSE  }
GGM <- pcor.shrink(sim.data, verbose=FALSE) # OPTIMAL
lambda <-attr(GGM, "lambda") 
#kappa(GGM, exact=TRUE, norm='2' )
r <-sm2vec(GGM)

# parameters of the mixture distribution used to compute p-values etc.
# c <- fdrtool(sm2vec(GGM), statistic="correlation")
# c$param
```
# Compute p-values
```{r ,  message = FALSE  }
## GENENET methods (empirical null fitting + std density)
## WATCH OUT:  the test must be in node order. Sort by node 2 and by node 1
ENF.test<-network.test.edges(GGM, fdr=TRUE, plot=FALSE, verbose = FALSE)
ENF.test<-ENF.test[order(ENF.test$node1,ENF.test$node2),]

#######################################
# MLE (shrunk density)
pval.shrunk<-p.shrunk(r,p,n,lambda)
# MLE (standard/std density)
# pval.std<-p.shrunk(r,p,n,0)
pval.standard <- p.standard ( r, p,n)

# MC
p.monte<-p.montecarlo(r,number,p,n,lambda)

# Estimate the critical value (cv.monte) at alpha with Monte Carlo
r.monte<-matrix(NA, length(r),number)
for (i in 1:number){
  r.data<-ggm.simulate.data(n,diag(p))
  r.monte.GGM<-ggm.estimate.pcor(r.data,lambda=lambda, verbose = FALSE )
  r.monte[,i]<-sm2vec(r.monte.GGM)
}
cv.values<-matrix(NA,1,ncol(r.monte))
for (i in 1:ncol(r.monte)){
  # 2 tails
  cv<-apply( -abs(r.monte),2, function(x) quantile(x,  probs = c((alpha/2)) ) )  
}
cv.monte<-mean(cv)   
cv.sd<-sd(cv)
```

# Check if they are uniformly distributed
```{r ,  message = FALSE}
hist(p.monte,20, col=rgb(1,1,1,0.5),main = c(),xlab="p-values",ylim=c(0,max(320)),cex.axis=1,cex.lab=1)
hist(pval.shrunk,20, col=rgb(0.7,0.7,0.7,1),add=T)
hist(ENF.test$pval,20, col=rgb(0.3,0.3,0.3,1),add=T)
legend("bottomright", c("MC", "Shrunk MLE", "ENF"), fill=c("white","gray","gray21"), cex = 1, bg="white")#,bty="n"


hist(p.monte,20, col=rgb(1,1,1,0.5),main = c(),xlab="p-values",ylim=c(0,max(320)),cex.axis=1,cex.lab=1)
hist(pval.shrunk,20, col=rgb(0.7,0.7,0.7,1),add=T)
hist(pval.standard,20, col=rgb(0.3,0.3,0.3,1),add=T)
legend("bottomright", c("MC", "Shrunk MLE", "Standard MLE"), fill=c("white","gray","gray21"), cex = 1, bg="white")

```
Conclusion: we see that using the standard density (which does not account for the shrinkage) produces biased results.

```{r ,  message = FALSE}

###### Estimate degrees of freedom  k
#### Shrunk
sim.pcor.MC<-ggm.simulate.pcor(p, 0)
sim.data.MC<- ggm.simulate.data( n , sim.pcor.MC)
GGM.MC <- pcor.shrink(sim.data.MC,lambda , verbose=FALSE) 
kappa(GGM.MC, exact=TRUE, norm='2' )
r.MC<-sm2vec(GGM.MC)
nlogL.shrunk <- function(k) {
  
  density.shrunk <- function(r.MC) {(  ((1-lambda)^2-r.MC^2) ^((k-3)*0.5)  )/( beta(0.5, 0.5*(k-1))*(1-lambda)*(1-lambda)^(k-3) )}
  
  f<-density.shrunk(r.MC)
  -sum(log(f))
}
### neg log Likelihood
k.fit.shrunk <-  mle(nlogL.shrunk, start = list(k = 100), method = "L-BFGS-B", lower = c(20),
                     upper = c(Inf))
summary(k.fit.shrunk)


######## Standard
nlogL.std <- function(k) {
  density.std <- function(r.MC) {(  ((1)^2-r.MC^2) ^((k-3)*0.5)  )/( beta(0.5, 0.5*(k-1)))}
  
  f<-density.std(r.MC)
  
  -sum(log(f))
}

k.fit.std <-  mle(nlogL.std, start = list(k = 50), method = "L-BFGS-B", lower = c(20),
                  upper = c(Inf))
summary(k.fit.std)
```

Plot the difference of the densities when k is estimated via maximum likelihood for both, the "shrunk"" and the standard density.
```{r}
density.shrunk <- function(x) {(  ((1-lambda)^2-x^2) ^(( k.fit.shrunk@coef[1]-3)*0.5)  )/( beta(0.5, 0.5*( k.fit.shrunk@coef[1]-1))*(1-lambda)*(1-lambda)^( k.fit.shrunk@coef[1]-3) )}
density.std <- function(x) {(  ((1)^2-x^2) ^((k.fit.std@coef[1]-3)*0.5)  )/( beta(0.5, 0.5*(k.fit.std@coef[1])-1))}
x<-(1-lambda)*c(-100:100)/100


plot(x, density.std(x) - density.shrunk(x),ylim=c(-1,1),type="l",pch=20,lwd = 3, 
     ylab="Prob density",xlab="pcorr",cex=1.1, cex.lab=1.1, cex.axis=1.1 ) 
abline(v =0)
abline(h =0)
legend("bottomright", 
       legend = c("Standard MLE - Shrunk MLE", paste("critical value at",alpha)), 
       col = c("black", 
               "black"), 
       pch = c("-","."),
       bg = "white", 
       pt.cex = c(1,4), 
       cex = 1, 
       text.col = "black", 
       horiz = F , 
       inset = c(0, 0.1))
abline(v=c(cv.monte,-cv.monte), col=c("black","black"),lty=c("dotted", "dotted") , lwd=c(2,2))

```
Conclusion: we see that using the standard density has thicker tails.

Plot the difference of the densities when k is estimated from a empirical the mixture distribution  for the standard density (a.k.a. ENF), as implemented in the R package GeneNet.

```{r ,  message = FALSE}
c <- fdrtool(sm2vec(GGM), statistic="correlation", plot=FALSE)
c$param
data.frame( k.fit.shrunk@coef[1], k.fit.std@coef[1], c$param[5]) 

density.shrunk <- function(x) {(  ((1-lambda)^2-x^2) ^(( k.fit.shrunk@coef[1]-3)*0.5)  )/( beta(0.5, 0.5*( k.fit.shrunk@coef[1]-1))*(1-lambda)*(1-lambda)^( k.fit.shrunk@coef[1]-3) )}
density.std <- function(x) {(  ((1)^2-x^2) ^((c$param[5]-3)*0.5)  )/( beta(0.5, 0.5*(c$param[5])-1))}
x<-(1-lambda)*c(-100:100)/100

plot(x, density.std(x) - density.shrunk(x) ,type="l",ylim=c(-1,1), col="black",pch=20,
     lwd = 3, xlab="pcorr", cex=1.1, cex.lab=1.1, cex.axis=1.1, ylab="Prob density" )+
  axis(side = 2, at = c(1,1))+
  abline(v =0)
abline(h =0)
legend("bottomright", 
       legend = c("ENF - Shrunk MLE", paste("critical value at",alpha)), 
       col = c("black", 
               "black"), 
       pch = c("-","."),
       bg = "white", 
       pt.cex = c(1,4), 
       cex = 1, 
       text.col = "black", 
       horiz = F , 
       inset = c(0, 0.1))
abline(v=c(cv.monte,-cv.monte), col=c("black","black"),lty=c("dotted", "dotted"), lwd=c(2,2))
```
Conclusion: we see that using the standard density has thicker tails.

